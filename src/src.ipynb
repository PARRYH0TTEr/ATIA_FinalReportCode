{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6994cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import loralib as lora\n",
    "from segment_anything.modeling.image_encoder import ImageEncoderViT, Block, Attention\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=100):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)) \n",
    "\n",
    "\n",
    "def applyLoRA_vit(model: ImageEncoderViT, r=16, alpha=16):\n",
    "    block: Block\n",
    "    for block in model.blocks:\n",
    "        attn: Attention = block.attn\n",
    "\n",
    "        old_qkv = attn.qkv\n",
    "        attn.qkv = lora.MergedLinear(\n",
    "            old_qkv.in_features,\n",
    "            old_qkv.out_features,\n",
    "            r=r,\n",
    "            enable_lora=[True, False, True],\n",
    "            fan_in_fan_out=False,\n",
    "            merge_weights=False,\n",
    "        )\n",
    "        attn.qkv.weight.data = old_qkv.weight.data.clone()\n",
    "        if old_qkv.bias is not None:\n",
    "            attn.qkv.bias.data = old_qkv.bias.data.clone()\n",
    "\n",
    "        old_proj = attn.proj\n",
    "        attn.proj = lora.Linear(\n",
    "            old_proj.in_features,\n",
    "            old_proj.out_features,\n",
    "            r=r,\n",
    "            fan_in_fan_out=False,\n",
    "            merge_weights=False,\n",
    "        )\n",
    "        attn.proj.weight.data = old_proj.weight.data.clone()\n",
    "        if old_proj.bias is not None:\n",
    "            attn.proj.bias.data = old_proj.bias.data.clone()\n",
    "\n",
    "\n",
    "def applyLoRA_tinyvit(model, r=16, alpha=16):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, \"blocks\"):  # BasicLayer has blocks\n",
    "            for block in layer.blocks:\n",
    "                if hasattr(block, \"attn\"):\n",
    "                    attn = block.attn\n",
    "                    \n",
    "                    old_qkv = attn.qkv\n",
    "                    attn.qkv = lora.MergedLinear(\n",
    "                        old_qkv.in_features,\n",
    "                        old_qkv.out_features,\n",
    "                        r=r,\n",
    "                        enable_lora=[True, False, True],\n",
    "                        fan_in_fan_out=False,\n",
    "                        merge_weights=False,\n",
    "                    )\n",
    "                    attn.qkv.weight.data = old_qkv.weight.data.clone()\n",
    "                    if old_qkv.bias is not None:\n",
    "                        attn.qkv.bias.data = old_qkv.bias.data.clone()\n",
    "\n",
    "                    old_proj = attn.proj\n",
    "                    attn.proj = lora.Linear(\n",
    "                        old_proj.in_features,\n",
    "                        old_proj.out_features,\n",
    "                        r=r,\n",
    "                        fan_in_fan_out=False,\n",
    "                        merge_weights=False,\n",
    "                    )\n",
    "                    attn.proj.weight.data = old_proj.weight.data.clone()\n",
    "                    if old_proj.bias is not None:\n",
    "                        attn.proj.bias.data = old_proj.bias.data.clone()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def applyBitFit_vit(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for name, param in model.image_encoder.named_parameters():\n",
    "        if name.endswith(\".bias\"):\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "def applyBitFit_tinyvit(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for name, param in model.image_encoder.named_parameters():\n",
    "        if name.endswith(\".bias\"):\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "def bitfit_state_dict(model):\n",
    "    sd = model.state_dict()\n",
    "    keep = OrderedDict()\n",
    "    for k, v in sd.items():\n",
    "        mod = model\n",
    "        try:\n",
    "            param = dict(model.named_parameters())[k]\n",
    "            if param.requires_grad and k.endswith(\".bias\"):\n",
    "                keep[k] = v\n",
    "        \n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def load_bitfit_state_dict(model, bias_sd, strict = False):\n",
    "    model.load_state_dict(bias_sd, strict=strict)\n",
    "\n",
    "\n",
    "def diceLoss(predictionMask, targetMask, eps=1e-6):\n",
    "    pred = predictionMask.sigmoid().flatten(1)\n",
    "    target = targetMask.float().flatten(1)\n",
    "    intersection = (pred * target).sum(-1)\n",
    "    union = pred.sum(-1) + target.sum(-1)\n",
    "    dice = (2 * intersection + eps) / (union + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def computeIoU(predictionMask, targetMask, threshold=0.5, eps=1e-6):\n",
    "    predictionBin = (predictionMask.sigmoid() > threshold).float()\n",
    "    targetBin = targetMask.float()\n",
    "    \n",
    "    intersection = (predictionBin * targetBin).sum()\n",
    "    union = predictionBin.sum() + targetBin.sum() - intersection\n",
    "    \n",
    "    return (intersection + eps) / (union + eps)\n",
    "\n",
    "def computeDice(predictionMask, targetMask, threshold=0.5, eps=1e-6):\n",
    "    predictionBin = (predictionMask.sigmoid() > threshold).float()\n",
    "    targetBin = targetMask.float()\n",
    "    \n",
    "    intersection = (predictionBin * targetBin).sum()\n",
    "    union = predictionBin.sum() + targetBin.sum()\n",
    "\n",
    "    dice = (2 * intersection + eps) / (union + eps)\n",
    "    return dice\n",
    "\n",
    "\n",
    "def trainOneEpoch(model, dataloader, optimizer, scheduler, device, currModelName):\n",
    "    model.train()\n",
    "    totalLoss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        images = batch[\"image\"].to(device)#.unsqueeze(0)\n",
    "        masks_gt = batch[\"mask\"].to(device)#.unsqueeze(0)\n",
    "        points = batch[\"points\"].to(device)#.unsqueeze(0)\n",
    "        labels = batch[\"labels\"].to(device)#.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        imageEmbeddings = model.image_encoder(images)\n",
    "\n",
    "        sparsePromptEmbeddings, densePromptEmbeddings = model.prompt_encoder(\n",
    "            points=(points, labels),\n",
    "            boxes=None,\n",
    "            masks=None,\n",
    "        )\n",
    "\n",
    "        if (currModelName == \"tinySam\"):\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings\n",
    "            )\n",
    "\n",
    "            masks_pred = F.interpolate(\n",
    "                masks_pred,\n",
    "                size=masks_gt.shape[-2:],\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            )\n",
    "\n",
    "            if (masks_pred.shape[1] != masks_gt.shape[1]):\n",
    "                masks_pred = masks_pred[:, 0:1, :, :]\n",
    "        else:\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings,\n",
    "                multimask_output=False\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # loss = diceLoss(masks_pred, masks_gt) + F.binary_cross_entropy_with_logits(\n",
    "        #     masks_pred, masks_gt\n",
    "        # )\n",
    "\n",
    "        loss = diceLoss(masks_pred, masks_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        totalLoss += loss.item()\n",
    "\n",
    "    return totalLoss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluateValidationOneEpoch(model, dataloader, device, currModelName):\n",
    "    model.train(False)\n",
    "    totalLoss = []\n",
    "    totalIoU = []\n",
    "    totalDice = []\n",
    "    # totalLoss = 0.0\n",
    "    # totalIoU = 0.0\n",
    "    # totalDice = 0.0\n",
    "    # numSamples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        images = batch[\"image\"].to(device)#.unsqueeze(0)\n",
    "        masks_gt = batch[\"mask\"].to(device)#.unsqueeze(0)\n",
    "        points = batch[\"points\"].to(device)#.unsqueeze(0)\n",
    "        labels = batch[\"labels\"].to(device)#.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        imageEmbeddings = model.image_encoder(images)\n",
    "\n",
    "        sparsePromptEmbeddings, densePromptEmbeddings = model.prompt_encoder(\n",
    "            points=(points, labels),\n",
    "            boxes=None,\n",
    "            masks=None,\n",
    "        )\n",
    "\n",
    "        if (currModelName == \"tinySam\"):\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings\n",
    "            )\n",
    "\n",
    "            masks_pred = F.interpolate(\n",
    "                masks_pred,\n",
    "                size=masks_gt.shape[-2:],\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            )\n",
    "\n",
    "            if (masks_pred.shape[1] != masks_gt.shape[1]):\n",
    "                masks_pred = masks_pred[:, 0:1, :, :]\n",
    "        else:\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings,\n",
    "                multimask_output=False\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # loss = diceLoss(masks_pred, masks_gt) + F.binary_cross_entropy_with_logits(\n",
    "        #     masks_pred, masks_gt\n",
    "        # )\n",
    "\n",
    "        loss = diceLoss(masks_pred, masks_gt)\n",
    "        totalLoss.append(loss.item())\n",
    "        # totalLoss += loss.item()\n",
    "\n",
    "        IoU = computeIoU(masks_pred, masks_gt)\n",
    "        totalIoU.append(IoU.item())\n",
    "        # totalIoU += IoU.item()\n",
    "\n",
    "        Dice = computeDice(masks_pred, masks_gt)\n",
    "        totalDice.append(Dice.item())\n",
    "        # totalDice += Dice.item()\n",
    "\n",
    "        # numSamples += 1\n",
    "\n",
    "    # return totalLoss / numSamples, totalIoU / numSamples, totalDice / numSamples\n",
    "    model.train(True)\n",
    "    return np.mean(totalLoss), np.mean(totalIoU), np.mean(totalDice)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluateTestOneEpoch(model, dataloader, device, currModelName):\n",
    "    model.train(False)\n",
    "    totalLoss = []\n",
    "    totalIoU = []\n",
    "    totalDice = []\n",
    "    # totalLoss = 0.0\n",
    "    # totalIoU = 0.0\n",
    "    # totalDice = 0.0\n",
    "    numSamples = 0\n",
    "    peakMemoryUsage = []\n",
    "    inferenceTimes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "        images = batch[\"image\"].to(device)#.unsqueeze(0)\n",
    "        masks_gt = batch[\"mask\"].to(device)#.unsqueeze(0)\n",
    "        points = batch[\"points\"].to(device)#.unsqueeze(0)\n",
    "        labels = batch[\"labels\"].to(device)#.unsqueeze(0)\n",
    "\n",
    "        \n",
    "        startTime = time.perf_counter()\n",
    "        imageEmbeddings = model.image_encoder(images)\n",
    "\n",
    "        sparsePromptEmbeddings, densePromptEmbeddings = model.prompt_encoder(\n",
    "            points=(points, labels),\n",
    "            boxes=None,\n",
    "            masks=None,\n",
    "        )\n",
    "\n",
    "        if (currModelName == \"tinySam\"):\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings\n",
    "            )\n",
    "\n",
    "            masks_pred = F.interpolate(\n",
    "                masks_pred,\n",
    "                size=masks_gt.shape[-2:],\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            )\n",
    "\n",
    "            if (masks_pred.shape[1] != masks_gt.shape[1]):\n",
    "                masks_pred = masks_pred[:, 0:1, :, :]\n",
    "        else:\n",
    "            masks_pred, iousPredictions = model.mask_decoder(\n",
    "                image_embeddings=imageEmbeddings,\n",
    "                image_pe=model.prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparsePromptEmbeddings,\n",
    "                dense_prompt_embeddings=densePromptEmbeddings,\n",
    "                multimask_output=False\n",
    "            )\n",
    "\n",
    "        endTime = time.perf_counter()\n",
    "        inferenceTimes.append(endTime - startTime)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            peakMemoryDuringPrediction = torch.cuda.max_memory_allocated(device)\n",
    "            peakMemoryUsage.append(peakMemoryDuringPrediction)\n",
    "\n",
    "\n",
    "        # loss = diceLoss(masks_pred, masks_gt) + F.binary_cross_entropy_with_logits(\n",
    "        #     masks_pred, masks_gt\n",
    "        # )\n",
    "\n",
    "        loss = diceLoss(masks_pred, masks_gt)\n",
    "        totalLoss.append(loss.item())\n",
    "        # totalLoss += loss.item()\n",
    "\n",
    "        IoU = computeIoU(masks_pred, masks_gt)\n",
    "        totalIoU.append(IoU.item())\n",
    "        # totalIoU += IoU.item()\n",
    "\n",
    "        Dice = computeDice(masks_pred, masks_gt)\n",
    "        totalDice.append(Dice.item())\n",
    "        # totalDice += Dice.item()\n",
    "\n",
    "        numSamples += 1\n",
    "\n",
    "    # Get max memory and convert to MB\n",
    "    maxMemory = np.max(peakMemoryUsage) / (1024 ** 2) if peakMemoryUsage else 0\n",
    "\n",
    "    # Get mean latency and convert to ms\n",
    "    avgInferenceLatency = np.mean(inferenceTimes) * 1000 if inferenceTimes else 0\n",
    "\n",
    "    # return totalLoss, totalIoU, totalDice, numSamples, maxMemory, avgInferenceLatency\n",
    "    model.train(True)\n",
    "    return totalLoss, totalIoU, totalDice, numSamples, maxMemory, avgInferenceLatency\n",
    "\n",
    "def normalizeImage(imgChw: torch.Tensor):\n",
    "    PIXEL_MEAN = torch.tensor([123.675, 116.28, 103.53]) / 255.0\n",
    "    PIXEL_STD  = torch.tensor([58.395, 57.12, 57.375]) / 255.0\n",
    "\n",
    "    imgChw = imgChw / 255.0\n",
    "    \n",
    "    return (imgChw - PIXEL_MEAN[:, None, None]) / PIXEL_STD[:, None, None]\n",
    "\n",
    "class CityscapesCars(Dataset):\n",
    "\n",
    "    def __init__(self, imageFiles, labelFiles, targetClass=26):\n",
    "        \n",
    "        self.imageFiles = imageFiles\n",
    "        self.labelFiles = labelFiles\n",
    "        self.targetClass = targetClass\n",
    "\n",
    "        self.samImageEncoderSize = 1024 # Defined in the ImageEncoderViT\n",
    "        self.transform = ResizeLongestSide(self.samImageEncoderSize)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFiles)\n",
    "    \n",
    "    def __getitem__(self,  index):\n",
    "\n",
    "        image = cv2.imread(self.imageFiles[index])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        originalImageH, originalImageW = image.shape[:2]\n",
    "\n",
    "        image_resized = cv2.resize(image, (1024, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "        image_tensor = torch.as_tensor(image_resized).permute(2, 0, 1).float()\n",
    "        image_tensor = normalizeImage(image_tensor)\n",
    "\n",
    "        labels = cv2.imread(self.labelFiles[index], cv2.IMREAD_UNCHANGED)\n",
    "        mask = (labels == self.targetClass).astype(np.uint8)\n",
    "\n",
    "        # Point prompts inside the mask (positive)\n",
    "        posPointPromptsAmount = 2\n",
    "        ys, xs = np.where(mask > 0)\n",
    "        posCoords = []\n",
    "        for _ in range(posPointPromptsAmount):\n",
    "            posIndex = np.random.randint(0, len(xs))\n",
    "            posCoords.append([xs[posIndex], ys[posIndex]])\n",
    "\n",
    "        posCoords = np.array(posCoords, dtype=np.float32)\n",
    "        posLabels = np.ones(posPointPromptsAmount, dtype=np.int32)\n",
    "        # pointCoords = np.array([[xs[indexChoice], ys[indexChoice]]], dtype=np.float32)\n",
    "        # pointLabels = np.array([1], dtype=np.int32)\n",
    "\n",
    "        # Point prompts outside the mask (negative)\n",
    "        negPointPromptsAmount = 3\n",
    "        neg_ys, neg_xs = np.where(mask == 0)\n",
    "        negCoords = []\n",
    "        for _ in range(negPointPromptsAmount):\n",
    "            negIndex = np.random.randint(0, len(neg_xs))\n",
    "            negCoords.append([neg_xs[negIndex], neg_ys[negIndex]])\n",
    "\n",
    "        negCoords = np.array(negCoords, dtype=np.float32)\n",
    "        negLabels = np.zeros(negPointPromptsAmount, dtype=np.int32)\n",
    "\n",
    "        pointCoords = np.vstack([posCoords, negCoords])\n",
    "        pointLabels = np.concatenate([posLabels, negLabels])\n",
    "\n",
    "        scaleX = 1024 / originalImageW\n",
    "        scaleY = 1024 / originalImageH\n",
    "\n",
    "        pointCoords = pointCoords * np.array([scaleX, scaleY], dtype=np.float32)\n",
    "\n",
    "        mask_resized = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        sample = {\n",
    "            \"image\":  image_tensor, #torch.tensor(image).permute(2, 0, 1).float(),\n",
    "            \"mask\": torch.tensor(mask_resized).unsqueeze(0).float(),\n",
    "            \"points\": torch.tensor(pointCoords).float(),\n",
    "            \"labels\": torch.tensor(pointLabels).long()\n",
    "        }\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def imageHasCar(labelFile, targetClass=26):\n",
    "    labels = cv2.imread(labelFile, cv2.IMREAD_UNCHANGED)\n",
    "    return (labels == targetClass).any()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ModelContainer():\n",
    "\n",
    "    def __init__(self, modelVariant, modelVariantPredictorClass, modelVariantName, modelBaseName):\n",
    "        self.modelVariant = modelVariant\n",
    "        self.modelVariantPredictorClass = modelVariantPredictorClass\n",
    "        self.modelVariantName = modelVariantName\n",
    "        self.modelBaseName = modelBaseName\n",
    "\n",
    "\n",
    "\n",
    "def samplePoints(mask, numPositivePoints, numNegativePoints):\n",
    "    ysPos, xsPos = np.where(mask > 0)\n",
    "    ysNeg, xsNeg = np.where(mask == 0)\n",
    "\n",
    "    posIndices = np.random.choice(len(xsPos), size=numPositivePoints, replace=False)\n",
    "    negIndices = np.random.choice(len(xsNeg), size=numNegativePoints, replace=False)\n",
    "\n",
    "    posPoints = np.stack([xsPos[posIndices], ysPos[posIndices]], axis=1)\n",
    "    negPoints = np.stack([xsNeg[negIndices], ysNeg[negIndices]], axis=1)\n",
    "\n",
    "    points = np.concatenate([posPoints, negPoints], axis=0).astype(np.float32)\n",
    "    labels = np.concatenate([np.ones(len(posPoints)), np.zeros(len(negPoints))], axis=0).astype(np.int32)\n",
    "\n",
    "    return points, labels\n",
    "\n",
    "def visualizeModelComparison(imageFile, labelFile, baselineModels, finetunedModels, device):\n",
    "    image = cv2.imread(imageFile)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    labels = cv2.imread(labelFile, cv2.IMREAD_UNCHANGED)\n",
    "    gtMask = (labels == 26).astype(np.uint8)\n",
    "\n",
    "    H, W = image.shape[:2]\n",
    "\n",
    "    numPositivePoints = 2\n",
    "    numNegativePoints = 3\n",
    "    pointsOrig, labelsResized = samplePoints(gtMask, numPositivePoints, numNegativePoints)\n",
    "\n",
    "    # pointsOrig = np.array([[1850, 550], [1250, 450], [1150, 750], [500, 500], [900, 250]])\n",
    "    # labelsResized = np.array([1, 1, 0, 0, 0])\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    show_mask(gtMask, axs[0])\n",
    "    show_points(pointsOrig, labelsResized, axs[0])\n",
    "    axs[0].set_title(\"Input image\")\n",
    "    # axs[0].axis('off')\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "    axs[0].set_xlabel(\"Ground truth w/ point prompts\")\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        # axs[i].axis('off')\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "\n",
    "    for j, mdl in enumerate(baselineModels):\n",
    "        predictor = mdl.modelVariantPredictorClass(mdl.modelVariant)\n",
    "        predictor.set_image(image)\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            point_coords=pointsOrig,\n",
    "            point_labels=labelsResized\n",
    "        )\n",
    "\n",
    "        # masks, scores, _ = predictor.predict()\n",
    "\n",
    "        bestMask = masks[scores.argmax()]\n",
    "\n",
    "        axs[j+1].imshow(image)\n",
    "        show_mask(bestMask, axs[j+1])\n",
    "        axs[j+1].set_title(f\"{mdl.modelBaseName} ({mdl.modelVariantName})\")\n",
    "        axs[j+1].set_xlabel(\"Predicted mask\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./results/BaselinePredictionsComparison.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 8))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i in range(len(finetunedModels)):\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks([])\n",
    "\n",
    "    for j, mdl in enumerate(finetunedModels):\n",
    "        predictor = mdl.modelVariantPredictorClass(mdl.modelVariant)\n",
    "        predictor.set_image(image)\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            point_coords=pointsOrig,\n",
    "            point_labels=labelsResized\n",
    "        )\n",
    "\n",
    "        bestMask = masks[scores.argmax()]\n",
    "\n",
    "        axs[j].imshow(image)\n",
    "        show_mask(bestMask, axs[j])\n",
    "        axs[j].set_title(f\"{mdl.modelBaseName} ({mdl.modelVariantName})\")\n",
    "        axs[j].set_xlabel(\"Predicted mask\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./results/FinetunedPredictionsComparison.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def DEBUG_CountTrainableParameters(model):\n",
    "    total = 0\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            total += p.numel()\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "def TestModelVariant(testLoss, testIoU, testDice, maxMemoryUsed, avgInferenceLatency, resultsPath, modelVariantName, modelBaseName):\n",
    "    \n",
    "    print(\"\\nTesting the model..\")\n",
    "    \n",
    "    avgTestLoss = np.mean(testLoss)\n",
    "    avgTestIoU = np.mean(testIoU)\n",
    "    avgTestDice = np.mean(testDice)\n",
    "    stdTestLoss = np.std(testLoss)\n",
    "    stdTestIoU = np.std(testIoU)\n",
    "    stdTestDice = np.std(testDice)\n",
    "    throughput = 1000 / avgInferenceLatency\n",
    "\n",
    "    print(\"\\n======== Test Results ========\")\n",
    "    print(f\"Test mLoss: {avgTestLoss:.4f}\")\n",
    "    print(f\"Test mIoU: {avgTestIoU:.4f}\")\n",
    "    print(f\"Test mDice: {avgTestDice:.4f}\")\n",
    "    print(f\"Test maxMemoryUsed: {maxMemoryUsed:.2f} MB\")\n",
    "    print(f\"Test avgInferenceLatency: {avgInferenceLatency:.2f} ms\")\n",
    "    print(\"==============================\\n\")\n",
    "    print(\"\\n ==== DEBUG =====\")\n",
    "    print(f\"loss: {testLoss}\")\n",
    "    print(f\"IoU: {testIoU}\")\n",
    "    print(f\"Dice: {testDice}\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    testResultsCsvFile = os.path.join(resultsPath, f\"{modelVariantName}_{modelBaseName}_test_results.csv\")\n",
    "    with open(testResultsCsvFile, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Mean Test Loss\", \n",
    "                         \"Std Test Loss\",\n",
    "                         \"Mean Test IoU\",\n",
    "                         \"Std Test IoU\", \n",
    "                         \"Mean Test Dice\",\n",
    "                         \"Std Test Dice\", \n",
    "                         \"Test maxMemoryUsed\", \n",
    "                         \"Mean Test InferenceLatency\",\n",
    "                         \"Throughput\"])\n",
    "        \n",
    "        writer.writerow([f\"{avgTestLoss:.3f}\",\n",
    "                         f\"{stdTestLoss:.2f}\",\n",
    "                         f\"{avgTestIoU:.3f}\",\n",
    "                         f\"{stdTestIoU:.2f}\", \n",
    "                         f\"{avgTestDice:.3f}\",\n",
    "                         f\"{stdTestDice:.2f}\", \n",
    "                         f\"{maxMemoryUsed:.2f}\", \n",
    "                         f\"{avgInferenceLatency:.2f}\",\n",
    "                         f\"{throughput:.2f}\"])\n",
    "\n",
    "\n",
    "    print(\"Testing finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df51170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend([\n",
    "    \"./segment-anything\",\n",
    "    \"./MobileSAM\",\n",
    "    \"./TinySAM\"\n",
    "])\n",
    "\n",
    "from segment_anything import sam_model_registry as samModelReg, SamPredictor as samPred, build_sam, build_sam_vit_b, build_sam_vit_h, build_sam_vit_l\n",
    "from mobile_sam import sam_model_registry as mobileSamModelReg, SamPredictor as mobileSamPred, build_sam_vit_t as mobile_build_sam_vit_t\n",
    "from tinysam import sam_model_registry as tinySamModelReg, SamPredictor as tinySamPred, build_sam_vit_t as tiny_build_sam_vit_t\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Setting up each of the models and their respective predictors\n",
    "\n",
    "#SAM\n",
    "samCheckpointViTB = \"./model_weights/sam_vit_b_01ec64.pth\"\n",
    "samCheckpointViTH = \"./model_weights/sam_vit_h_4b8939.pth\"\n",
    "samCheckpointViTL = \"./model_weights/sam_vit_l_0b3195.pth\"\n",
    "mobileSamCheckpoint = \"./model_weights/mobile_sam.pt\"\n",
    "tinySamCheckpoint = \"./model_weights/tinysam_42.3.pth\"\n",
    "\n",
    "# LoRASam = build_sam_vit_l(checkpoint=samCheckpointViTL)\n",
    "# sam = build_sam_vit_h(checkpoint=samCheckpointViTH)\n",
    "BaselineSam = build_sam_vit_b(checkpoint=samCheckpointViTB)\n",
    "BaselineMobileSam = mobile_build_sam_vit_t(checkpoint=mobileSamCheckpoint)\n",
    "BaselineTinySam = tiny_build_sam_vit_t(checkpoint=tinySamCheckpoint)\n",
    "\n",
    "LoRASam = build_sam_vit_b(checkpoint=samCheckpointViTB)\n",
    "LoRAMobileSam = mobile_build_sam_vit_t(checkpoint=mobileSamCheckpoint)\n",
    "LoRATinySam = tiny_build_sam_vit_t(checkpoint=tinySamCheckpoint)\n",
    "\n",
    "BitFitSam = build_sam_vit_b(checkpoint=samCheckpointViTB)\n",
    "BitFitMobileSam = mobile_build_sam_vit_t(checkpoint=mobileSamCheckpoint)\n",
    "BitFitTinySam = tiny_build_sam_vit_t(checkpoint=tinySamCheckpoint)\n",
    "print(\"Built the models\")\n",
    "\n",
    "applyLoRA_vit(LoRASam.image_encoder)\n",
    "applyLoRA_tinyvit(LoRAMobileSam.image_encoder)\n",
    "applyLoRA_tinyvit(LoRATinySam.image_encoder)\n",
    "print(\"Applied LoRA\")\n",
    "\n",
    "lora.mark_only_lora_as_trainable(LoRASam)\n",
    "lora.mark_only_lora_as_trainable(LoRAMobileSam)\n",
    "lora.mark_only_lora_as_trainable(LoRATinySam)\n",
    "print(\"Freezing everything except LoRA\")\n",
    "\n",
    "applyBitFit_vit(BitFitSam)\n",
    "applyBitFit_tinyvit(BitFitMobileSam)\n",
    "applyBitFit_tinyvit(BitFitTinySam)\n",
    "print(\"Applied BitFit\")\n",
    "\n",
    "BaselineSam.to(device=device)\n",
    "BaselineMobileSam.to(device=device)\n",
    "BaselineTinySam.to(device=device)\n",
    "\n",
    "LoRASam.to(device=device)\n",
    "LoRAMobileSam.to(device=device)\n",
    "LoRATinySam.to(device=device)\n",
    "\n",
    "BitFitSam.to(device=device)\n",
    "BitFitMobileSam.to(device=device)\n",
    "BitFitTinySam.to(device=device)\n",
    "\n",
    "BaselineSam.train(False)\n",
    "BaselineMobileSam.train(False)\n",
    "BaselineTinySam.train(False)\n",
    "\n",
    "LoRASam.train()\n",
    "LoRAMobileSam.train()\n",
    "LoRATinySam.train()\n",
    "\n",
    "BitFitSam.train()\n",
    "BitFitMobileSam.train()\n",
    "BitFitTinySam.train()\n",
    "\n",
    "# currModel = \"tinySam\"\n",
    "\n",
    "# if (currModel == \"mobileSam\"):\n",
    "#     model = mobileSam\n",
    "#     predictorClass = mobileSamPred\n",
    "#     modelName = currModel\n",
    "# elif (currModel == \"tinySam\"):\n",
    "#     model = tinySam\n",
    "#     predictorClass = tinySamPred\n",
    "#     modelName = currModel\n",
    "# else:\n",
    "#     model = sam\n",
    "#     predictorClass = samPred\n",
    "#     modelName = currModel\n",
    "# print(f\"Current model is: {currModel}\")\n",
    "\n",
    "BaselineSamModelContainer = ModelContainer(BaselineSam, samPred, \"Baseline\", \"sam\")\n",
    "BaselineMobileSamModelContainer = ModelContainer(BaselineMobileSam, mobileSamPred, \"Baseline\", \"mobileSam\")\n",
    "BaselineTinySamModelContainer = ModelContainer(BaselineTinySam, tinySamPred, \"Baseline\", \"tinySam\")\n",
    "\n",
    "baselineModelContainerList = [\n",
    "    BaselineSamModelContainer,\n",
    "    BaselineMobileSamModelContainer,\n",
    "    BaselineTinySamModelContainer\n",
    "]\n",
    "\n",
    "LoRASamModelContainer = ModelContainer(LoRASam, samPred, \"LoRA\", \"sam\")\n",
    "LoRAMobileSamModelContainer = ModelContainer(LoRAMobileSam, mobileSamPred, \"LoRA\", \"mobileSam\")\n",
    "LoRATinySamContainer = ModelContainer(LoRATinySam, tinySamPred, \"LoRA\", \"tinySam\")\n",
    "\n",
    "BitFitSamModelContainer = ModelContainer(BitFitSam, samPred, \"BitFit\", \"sam\")\n",
    "BitFitMobileSamModelContainer = ModelContainer(BitFitMobileSam, mobileSamPred, \"BitFit\", \"mobileSam\")\n",
    "BitFitTinySamModelContainer = ModelContainer(BitFitTinySam, tinySamPred, \"BitFit\", \"tinySam\")\n",
    "\n",
    "# FOR TESTING ONLY -- REMOVE AFTER TESTING IS DONE\n",
    "# finetunedModelContainerList = [BitFitSamModelContainer]\n",
    "\n",
    "# finetunedModelContainerList = []\n",
    "\n",
    "finetunedModelContainerList = [LoRASamModelContainer,\n",
    "                               LoRAMobileSamModelContainer,\n",
    "                               LoRATinySamContainer,\n",
    "                               BitFitSamModelContainer,\n",
    "                               BitFitMobileSamModelContainer,\n",
    "                               BitFitTinySamModelContainer]\n",
    "\n",
    "print(\"\")\n",
    "trainImages = sorted(glob.glob(\"./Datasets/leftImg8bit/train/*/*_leftImg8bit.png\"))\n",
    "trainLabels = sorted(glob.glob(\"./Datasets/gtFine/train/*/*_labelIds.png\"))\n",
    "\n",
    "print(f\"trainImages length is: {len(trainImages)}\")\n",
    "print(f\"trainLabels length is: {len(trainLabels)}\")\n",
    "\n",
    "validationImages = sorted(glob.glob(\"./Datasets/leftImg8bit/val/*/*_leftImg8bit.png\"))\n",
    "validationLabels = sorted(glob.glob(\"./Datasets/gtFine/val/*/*_labelIds.png\"))\n",
    "\n",
    "\n",
    "# These images don't work, use a 20% split from validation data instead as test data\n",
    "# testImages = sorted(glob.glob(\"../Datasets/leftImg8bit/test/*/*_leftImg8bit.png\"))\n",
    "# testLabels = sorted(glob.glob(\"../Datasets/gtFine/test/*/*_labelIds.png\"))\n",
    "\n",
    "validationImages, testImages, validationLabels, testLabels = train_test_split(\n",
    "    validationImages, validationLabels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"validationImages length is: {len(validationImages)}\")\n",
    "print(f\"validationLabels length is: {len(validationLabels)}\")\n",
    "\n",
    "print(f\"testImages length is: {len(testImages)}\")\n",
    "print(f\"testLabels length is: {len(testLabels)}\")\n",
    "\n",
    "\n",
    "amountOfDataImages = 100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Sorting training data..\")\n",
    "filteredTrainImages, filteredTrainLabels = [], []\n",
    "for imageFile, labelFile in zip(trainImages, trainLabels):\n",
    "    # if len(filteredTrainImages) < amountOfDataImages:\n",
    "        if imageHasCar(labelFile, targetClass=26):\n",
    "            filteredTrainImages.append(imageFile)\n",
    "            filteredTrainLabels.append(labelFile)\n",
    "print(\"Finished sorting training data\")\n",
    "print(f\"Sorted training data has: {len(filteredTrainImages)} images, {len(filteredTrainLabels)} labels\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Sorting validation data..\")\n",
    "filteredValidationImages, filteredValidationLabels = [], []\n",
    "for imageFile, labelFile in zip(validationImages, validationLabels):\n",
    "    # if len(filteredValidationImages) < amountOfDataImages:\n",
    "        if imageHasCar(labelFile, targetClass=26):\n",
    "            filteredValidationImages.append(imageFile)\n",
    "            filteredValidationLabels.append(labelFile)\n",
    "print(\"Finished sorting validation data\")\n",
    "print(f\"Sorted validation data has: {len(filteredValidationImages)} images, {len(filteredValidationLabels)} labels\")\n",
    "\n",
    "\n",
    "# The test data provided in the Cityscapes gtFine dataset contains some unusuable data and thus we are then instead splitting\n",
    "#   the validation dataset into validation data (80%) and test data (20%)\n",
    "print(\"\")\n",
    "print(\"Sorting test data..\")\n",
    "filteredTestImages, filteredTestLabels = [], []\n",
    "for imageFile, labelFile in zip(testImages, testLabels):\n",
    "    # if len(filteredTestImages) < amountOfDataImages:\n",
    "        if imageHasCar(labelFile, targetClass=26):\n",
    "            filteredTestImages.append(imageFile)\n",
    "            filteredTestLabels.append(labelFile)\n",
    "print(\"Finished sorting test data\")\n",
    "print(f\"Sorted test data has: {len(filteredTestImages)} images, {len(filteredTestLabels)} labels\")\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Initializing Training DataSet and DataLoader\")\n",
    "trainDataset = CityscapesCars(filteredTrainImages, filteredTrainLabels, targetClass=26)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"Initializing Validation DataSet and DataLoader\")\n",
    "validationDataset = CityscapesCars(filteredValidationImages, filteredValidationLabels, targetClass=26)\n",
    "validationLoader = DataLoader(validationDataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(\"Initializing Test DataSet and DataLoader\")\n",
    "testDataset = CityscapesCars(filteredTestImages, filteredTestLabels, targetClass=26)\n",
    "testLoader = DataLoader(testDataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Removes results folder complete, including all sub-directories and files\n",
    "if os.path.exists(\"./results\"):\n",
    "    shutil.rmtree(\"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(modelVariant, modelVariantPredictorClass, modelVariantName, modelBaseName, resultsPath):\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(f\"Current model variant: {modelVariantName}\")\n",
    "    print(f\"Current model base: {modelBaseName}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(f\"Current model trainable params: {DEBUG_CountTrainableParameters(modelVariant)}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Creating optimizer\")\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, modelVariant.parameters()), lr=1e-4, weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    # Setting this to some high amount. Early stopping should (hoepfully) be hit before then.\n",
    "    numEpochs = 40\n",
    "    stepsPerEpoch = len(trainLoader)\n",
    "    totalSteps = numEpochs * stepsPerEpoch\n",
    "\n",
    "\n",
    "    warmupEpochs = 5\n",
    "    warmupSteps = warmupEpochs * stepsPerEpoch\n",
    "    warmupScheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        start_factor=0.1,\n",
    "        total_iters=warmupSteps\n",
    "    )\n",
    "\n",
    "    cosineScheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=totalSteps - warmupSteps,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        optimizer, schedulers=[warmupScheduler, cosineScheduler], milestones=[warmupSteps]\n",
    "    )\n",
    "\n",
    "    trainingLoss = []\n",
    "    validationLoss = []\n",
    "    validationIoU = []\n",
    "    validationDice = []\n",
    "\n",
    "    \n",
    "    earlyStopping_Patience = 5\n",
    "    earlyStopping_BestSeenValidationLoss = float(\"inf\")\n",
    "    earlyStopping_BestEpochSeen = 0\n",
    "    earlyStopping_PatienceCounter = 0\n",
    "    bestWeights = {}\n",
    "\n",
    "    # resultsPath = f\"./results/{modelVariantName}/{modelBaseName}/\"\n",
    "\n",
    "    # os.makedirs(resultsPath, exist_ok=True)\n",
    "\n",
    "    print(\"Starting training..\")\n",
    "    for epochIndex, epoch in enumerate(range(numEpochs)):\n",
    "\n",
    "        loss = trainOneEpoch(modelVariant, trainLoader, optimizer, scheduler, device, modelBaseName)\n",
    "        trainingLoss.append(loss)\n",
    "\n",
    "        valLoss, valIoU, valDice = evaluateValidationOneEpoch(modelVariant, validationLoader, device, modelBaseName)\n",
    "        validationLoss.append(valLoss)\n",
    "        validationIoU.append(valIoU)\n",
    "        validationDice.append(valDice)\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}, Validation Loss: {valLoss:.4f}, Validation IoU: {valIoU:.4f}, Validation Dice: {valDice:.4f}\")\n",
    "\n",
    "        epochResultsCsvFile = os.path.join(resultsPath, f\"{modelVariantName}_{modelBaseName}_epoch_results.csv\")\n",
    "        willWriteHeader = not os.path.exists(epochResultsCsvFile)\n",
    "        with open(epochResultsCsvFile, mode=\"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            if willWriteHeader:\n",
    "                writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val IoU\", \"Val Dice\"])\n",
    "\n",
    "            writer.writerow([epoch+1, f\"{loss:.6f}\", f\"{valLoss:.6f}\", f\"{valIoU:.6f}\", f\"{valDice:.6f}\"])\n",
    "\n",
    "        modelVariant.eval()\n",
    "\n",
    "        # Early stopping check\n",
    "        if valLoss < earlyStopping_BestSeenValidationLoss:\n",
    "            earlyStopping_BestSeenValidationLoss = valLoss\n",
    "            earlyStopping_BestEpochSeen = epochIndex\n",
    "            earlyStopping_PatienceCounter = 0\n",
    "\n",
    "            if modelVariantName == \"LoRA\":\n",
    "                bestWeights[f\"{modelBaseName}_{modelVariantName}\"] = lora.lora_state_dict(modelVariant)\n",
    "\n",
    "            if modelVariantName == \"BitFit\":\n",
    "                bestWeights[f\"{modelBaseName}_{modelVariantName}\"] = bitfit_state_dict(modelVariant)\n",
    "        else:\n",
    "            earlyStopping_PatienceCounter += 1\n",
    "\n",
    "        if earlyStopping_PatienceCounter >= earlyStopping_Patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epochIndex+1}\")\n",
    "            print(f\"Best epoch was {earlyStopping_BestEpochSeen+1} with validation loss {earlyStopping_BestSeenValidationLoss:.4f}\")\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            randomTestImageIndex = np.random.randint(0, len(trainDataset) - 1)\n",
    "            # print(f\"Random Index for prediction was: {randomTestImageIndex}\")\n",
    "\n",
    "            sample = trainDataset[randomTestImageIndex]\n",
    "\n",
    "            image_np = cv2.imread(filteredTrainImages[randomTestImageIndex])\n",
    "            image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            imageOriginalH, imageOriginalW = image_np.shape[:2]\n",
    "\n",
    "            trainH, trainW = 1024, 1024\n",
    "\n",
    "\n",
    "            # point_coords = sample[\"points\"].cpu().numpy()\n",
    "            # point_labels = sample[\"labels\"].cpu().numpy()\n",
    "\n",
    "            # px, py = sample[\"points\"][0].cpu().numpy()\n",
    "            # px = int(px * (imageOriginalW / trainW))\n",
    "            # py = int(py * (imageOriginalH / trainH))\n",
    "            # originalPointCoords = np.array([[px, py]])\n",
    "            # originalPointLabels =  sample[\"labels\"].cpu().numpy()\n",
    "            \n",
    "            points_resized = sample[\"points\"].cpu().numpy()\n",
    "            labels_resized = sample[\"labels\"].cpu().numpy()\n",
    "\n",
    "            points_orig = points_resized.copy()\n",
    "            points_orig[:, 0] = points_resized[:, 0] * (imageOriginalW / trainW)\n",
    "            points_orig[:, 1] = points_resized[:, 1] * (imageOriginalH / trainH)\n",
    "\n",
    "\n",
    "            predictor = modelVariantPredictorClass(modelVariant)\n",
    "            predictor.set_image(image_np)\n",
    "\n",
    "            # print(currModel)\n",
    "\n",
    "            if (modelBaseName == \"tinySam\"):\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=points_orig,\n",
    "                    point_labels=labels_resized\n",
    "                )\n",
    "            else:\n",
    "                masks, scores, logits = predictor.predict(\n",
    "                    point_coords=points_orig,\n",
    "                    point_labels=labels_resized,\n",
    "                    multimask_output=True\n",
    "                )\n",
    "            \n",
    "            \n",
    "            indexBest = int(scores.argmax())\n",
    "            maskShow = masks[indexBest]\n",
    "            scoreShow = float(scores[indexBest])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "            # Prediction Visualization\n",
    "            # axs[0][0].imshow(image_np)\n",
    "            # show_mask(maskShow, axs[0][0])\n",
    "            # show_points(points_orig, labels_resized, axs[0][0])\n",
    "            # axs[0][0].axis('off')\n",
    "            # axs[0][0].set_title(f\"Epoch {epoch+1}, Score: {scoreShow}\")\n",
    "\n",
    "            # Training Loss\n",
    "            axs[0].plot(range(1, len(trainingLoss) + 1), trainingLoss, marker=\"o\", label=\"Training Loss\")\n",
    "            axs[0].set_xlabel(\"Epoch\")\n",
    "            axs[0].set_ylabel(\"Loss\")\n",
    "            axs[0].set_title(f\"{modelBaseName} ({modelVariantName}) - Training Loss\")\n",
    "            axs[0].grid(False)\n",
    "            axs[0].legend()\n",
    "\n",
    "            # Validation Loss\n",
    "            # axs[1][0].plot(range(1, len(validationLoss) + 1), validationLoss, marker=\"o\", label=\"Validation Loss\")\n",
    "            # axs[1][0].set_xlabel(\"Epoch\")\n",
    "            # axs[1][0].set_ylabel(\"Loss\")\n",
    "            # axs[1][0].set_title(f\"{modelName} (LoRA) - Validation Loss\")\n",
    "            # axs[1][0].grid(True)\n",
    "            # axs[1][0].legend()\n",
    "\n",
    "            # Validation IoU\n",
    "            axs[1].plot(range(1, len(validationIoU) + 1), validationIoU, marker=\"o\", label=\"IoU\", color='green')\n",
    "            axs[1].plot(range(1, len(validationDice) + 1), validationDice, marker=\"^\", label=\"Dice\", color='magenta')\n",
    "            axs[1].set_xlabel(\"Epoch\")\n",
    "            axs[1].set_ylabel(\"Score\")\n",
    "            axs[1].set_title(f\"{modelBaseName} ({modelVariantName}) - Validation\")\n",
    "            axs[1].grid(False)\n",
    "            axs[1].legend()\n",
    "\n",
    "\n",
    "            plt.savefig(f\"{resultsPath}{modelVariantName}_{modelBaseName}_Epoch{epochIndex+1}_Aggregate.png\")\n",
    "            # plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            # Visualize a prediction with the current fine-tuning\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(image_np)\n",
    "            show_mask(maskShow, plt.gca())\n",
    "            show_points(points_orig, labels_resized, plt.gca())\n",
    "            plt.title(f\"{modelBaseName} ({modelVariantName}) - Epoch {epoch+1}, Score: {scoreShow}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(f\"{resultsPath}{modelVariantName}_{modelBaseName}_Epoch{epochIndex+1}_PredictionVisual\")\n",
    "            # plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            # Visualize all training loss seen up until now\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(range(1, len(trainingLoss) + 1), trainingLoss, marker=\"o\", label=\"Training Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(f\"{modelBaseName} ({modelVariantName}) - Training Loss\")\n",
    "            plt.grid(False)\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{resultsPath}{modelVariantName}_{modelBaseName}_Epoch{epochIndex+1}_TrainingLossGraph\")\n",
    "            # plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            # Visualize all validation loss seen up until now\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(range(1, len(validationLoss) + 1), validationLoss, marker=\"o\", label=\"Validation Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(f\"{modelBaseName} ({modelVariantName}) - Validation Loss\")\n",
    "            plt.grid(False)\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{resultsPath}{modelVariantName}_{modelBaseName}_Epoch{epochIndex+1}_ValidationLossGraph\")\n",
    "            # plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            # Visualize all IoU and Dice seen up until now\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(range(1, len(validationIoU) + 1), validationIoU, marker=\"o\", label=\"IoU\")\n",
    "            plt.plot(range(1, len(validationDice) + 1), validationDice, marker=\"^\", label=\"Dice\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Score\")\n",
    "            plt.title(f\"{modelBaseName} ({modelVariantName}) - Validation\")\n",
    "            plt.grid(False)\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{resultsPath}{modelVariantName}_{modelBaseName}_Epoch{epochIndex+1}_IoUDiceGraph\")\n",
    "            # plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        modelVariant.train()\n",
    "\n",
    "\n",
    "    print(\"Training finished\")\n",
    "\n",
    "    # Restoring best weights, if modelVariantName != \"baseline\"\n",
    "    if modelVariantName == \"LoRA\":\n",
    "        modelVariant.load_state_dict(bestWeights[f\"{modelBaseName}_{modelVariantName}\"], strict=False)\n",
    "\n",
    "    if modelVariantName == \"BitFit\":\n",
    "        load_bitfit_state_dict(modelVariant, bestWeights[f\"{modelBaseName}_{modelVariantName}\"])\n",
    "\n",
    "    testLoss, testIoU, testDice, numSamples, maxMemoryUsed, avgInferenceLatency = evaluateTestOneEpoch(modelVariant, testLoader, device, modelBaseName)\n",
    "\n",
    "\n",
    "    if (modelVariantName == \"LoRA\"):\n",
    "        LoRAWeightsPath = os.path.join(resultsPath, f\"{modelVariantName}_{modelBaseName}_lora.pth\")\n",
    "        torch.save(lora.lora_state_dict(modelVariant), LoRAWeightsPath)\n",
    "        print(f\"Saving LoRA checkpoint in: {LoRAWeightsPath}\")\n",
    "\n",
    "    if (modelVariantName == \"BitFit\"):\n",
    "        BitFitWeightsPath = os.path.join(resultsPath, f\"{modelVariantName}_{modelBaseName}_bitfit.pth\")\n",
    "        torch.save(bitfit_state_dict(modelVariant), BitFitWeightsPath)\n",
    "        print(f\"Saving BitFit checkpoint in: {BitFitWeightsPath}\")\n",
    "\n",
    "    return testLoss, testIoU, testDice, maxMemoryUsed, avgInferenceLatency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1331521",
   "metadata": {},
   "outputs": [],
   "source": [
    "allTestLosses = []\n",
    "allTestIoUs = []\n",
    "allTestDices = []\n",
    "allMaxMemoryUsed = []\n",
    "allAvgInferenceLatency = []\n",
    "modelNames = []\n",
    "\n",
    "DEBUG_QUICKTEST = False\n",
    "DEBUG_QUICKTEST_MODELCONTAINER = BitFitTinySamModelContainer\n",
    "\n",
    "\n",
    "if DEBUG_QUICKTEST:\n",
    "\n",
    "    resultsPath = f\"./results/{DEBUG_QUICKTEST_MODELCONTAINER.modelVariantName}/{DEBUG_QUICKTEST_MODELCONTAINER.modelBaseName}/\"\n",
    "    os.makedirs(resultsPath, exist_ok=True)\n",
    "\n",
    "    testLoss, testIoU, testDice, maxMemoryUsed, avgInferenceLatency = trainModel(DEBUG_QUICKTEST_MODELCONTAINER.modelVariant,\n",
    "            DEBUG_QUICKTEST_MODELCONTAINER.modelVariantPredictorClass,\n",
    "            DEBUG_QUICKTEST_MODELCONTAINER.modelVariantName,\n",
    "            DEBUG_QUICKTEST_MODELCONTAINER.modelBaseName,\n",
    "            resultsPath)\n",
    "\n",
    "    allTestLosses.append(testLoss) # Remember that testLoss is a list of numSamples testlosses\n",
    "    allTestIoUs.append(testIoU) # Remember that testIoU is a list of numSamples testIoUs\n",
    "    allTestDices.append(testDice) # Remember that testDice is a list of numSamples testDices\n",
    "    allMaxMemoryUsed.append(maxMemoryUsed)\n",
    "    allAvgInferenceLatency.append(avgInferenceLatency)\n",
    "    modelNames.append(f\"{DEBUG_QUICKTEST_MODELCONTAINER.modelBaseName} ({DEBUG_QUICKTEST_MODELCONTAINER.modelVariantName})\")\n",
    "else:\n",
    "    for mdlContainer in baselineModelContainerList:\n",
    "\n",
    "        resultsPath = f\"./results/{mdlContainer.modelVariantName}/{mdlContainer.modelBaseName}/\"\n",
    "        os.makedirs(resultsPath, exist_ok=True)\n",
    "\n",
    "        testLoss, testIoU, testDice, _, maxMemoryUsed, avgInferenceLatency = evaluateTestOneEpoch(mdlContainer.modelVariant,\n",
    "                                                                                           testLoader,\n",
    "                                                                                           device,\n",
    "                                                                                           mdlContainer.modelBaseName\n",
    "                                                                                           )\n",
    "        allTestLosses.append(testLoss) # Remember that testLoss is a list of numSamples testlosses\n",
    "        allTestIoUs.append(testIoU) # Remember that testIoU is a list of numSamples testIoUs\n",
    "        allTestDices.append(testDice) # Remember that testDice is a list of numSamples testDices\n",
    "        allMaxMemoryUsed.append(maxMemoryUsed)\n",
    "        allAvgInferenceLatency.append(avgInferenceLatency)\n",
    "        modelNames.append(f\"{mdlContainer.modelBaseName} ({mdlContainer.modelVariantName})\")\n",
    "\n",
    "        TestModelVariant(testLoss, \n",
    "                         testIoU, \n",
    "                         testDice, \n",
    "                         maxMemoryUsed, \n",
    "                         avgInferenceLatency, \n",
    "                         resultsPath, \n",
    "                         mdlContainer.modelVariantName, \n",
    "                         mdlContainer.modelBaseName)\n",
    "\n",
    "\n",
    "    for mdlContainer in finetunedModelContainerList:\n",
    "\n",
    "        resultsPath = f\"./results/{mdlContainer.modelVariantName}/{mdlContainer.modelBaseName}/\"\n",
    "        os.makedirs(resultsPath, exist_ok=True)\n",
    "\n",
    "        testLoss, testIoU, testDice, maxMemoryUsed, avgInferenceLatency = trainModel(mdlContainer.modelVariant,\n",
    "                                                                                        mdlContainer.modelVariantPredictorClass,\n",
    "                                                                                        mdlContainer.modelVariantName,\n",
    "                                                                                        mdlContainer.modelBaseName,\n",
    "                                                                                        resultsPath)\n",
    "        \n",
    "        allTestLosses.append(testLoss) # Remember that testLoss is a list of numSamples testlosses\n",
    "        allTestIoUs.append(testIoU) # Remember that testIoU is a list of numSamples testIoUs\n",
    "        allTestDices.append(testDice) # Remember that testDice is a list of numSamples testDices\n",
    "        allMaxMemoryUsed.append(maxMemoryUsed)\n",
    "        allAvgInferenceLatency.append(avgInferenceLatency)\n",
    "        modelNames.append(f\"{mdlContainer.modelBaseName} ({mdlContainer.modelVariantName})\")\n",
    "\n",
    "        TestModelVariant(testLoss, \n",
    "                         testIoU, \n",
    "                         testDice, \n",
    "                         maxMemoryUsed, \n",
    "                         avgInferenceLatency, \n",
    "                         resultsPath, \n",
    "                         mdlContainer.modelVariantName, \n",
    "                         mdlContainer.modelBaseName)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "modelVariantColors = {\n",
    "    \"Baseline\": \"blue\",\n",
    "    \"LoRA\": \"magenta\",\n",
    "    \"BitFit\": \"orange\"\n",
    "}\n",
    "\n",
    "# A 'name' in modelNames has the form: f\"{modelBaseName} ({modelVariantName})\"\n",
    "# Splitting the 'name' gives a list with: [f\"{modelBaseName}\", f\"{modelVariantName})\"]\n",
    "# Selecting the second item in the list and strip off the trailing \")\"\n",
    "# If the given 'name' isn't found, default to a \"gray\" color\n",
    "plotColors = [modelVariantColors.get(name.split(\"(\")[1].strip(\")\"), \"gray\") for name in modelNames]\n",
    "# labels = [name.split(\"(\")[1].strip(\")\") for name in modelNames]\n",
    "# modelBaseNames = [name.split(\"(\")[0] for name in modelNames]\n",
    "\n",
    "# IoU comparison plot\n",
    "plt.figure(figsize=(6,4))\n",
    "IoUMeans = np.mean(allTestIoUs, axis=1)\n",
    "IoUStds = np.std(allTestIoUs, axis=1)\n",
    "plt.bar(modelNames, IoUMeans, yerr=IoUStds, capsize=5, zorder=3, color=plotColors)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"IoU (mean + std)\")\n",
    "plt.title(\"IoU comparison of model variants\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/IoUComparison.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Dice comparison plot\n",
    "plt.figure(figsize=(6,4))\n",
    "DiceMeans = np.mean(allTestDices, axis=1)\n",
    "DiceStds = np.std(allTestDices, axis=1)\n",
    "plt.bar(modelNames, DiceMeans, yerr=DiceStds, capsize=5, zorder=3, color=plotColors)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Dice score (mean + std)\")\n",
    "plt.title(\"Dice score comparison of model variants\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/DiceComparison.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# maxMemory comparison plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(modelNames, allMaxMemoryUsed, zorder=3)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Peak allocated memory during inference (MB)\")\n",
    "plt.title(\"Memory footprint\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/MaxMemoryComparison.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# inferenceLatency comparison plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(modelNames, allAvgInferenceLatency, zorder=3)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Mean inference latency (ms)\")\n",
    "plt.title(\"Inference latency\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/AvgInferenceLatencyComparison.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Produce a comparison between the given models predictions\n",
    "if not DEBUG_QUICKTEST:\n",
    "    visualizeModelComparison(filteredTestImages[0],\n",
    "                            filteredTestLabels[0],\n",
    "                            baselineModelContainerList,\n",
    "                            finetunedModelContainerList,\n",
    "                            device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
